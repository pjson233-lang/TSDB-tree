# 修正后的性能测试结果总结

**测试时间**: 2025-11-29 17:04:58 - 17:06:17  
**测试范围**: Insert / Lookup / Scan (1-32线程)  
**数据规模**: 10,240,000 条记录 (1024 个 series × 10,000 条/series)

---

## 一、Insert 性能测试结果

### 1.1 真实吞吐 vs 写入峰值吞吐

| 线程数 | 真实吞吐 (Mops/sec) | 写入峰值 (Mops/sec) | 总时间 (ms) | Merge CPU Ratio |
|--------|-------------------|-------------------|------------|----------------|
| 1      | 48.5              | 74.5              | 211.0      | 90.3%          |
| 2      | 110.2             | 177.8             | 92.9       | 78.0%          |
| 4      | 58.8              | 331.2             | 174.1      | 88.3%          |
| 8      | 5.66              | 250.5             | 1809.0     | 98.9%          |
| 16     | 0.42              | 494.3             | 24306.6    | 99.9%          |
| 32     | 0.21              | 614.9             | 47795.2    | 99.9%          |

### 1.2 关键发现

#### ✅ **写入热路径性能优秀**
- **写入峰值吞吐**（Writer-only Throughput）从 74.5 Mops/sec (1线程) 提升到 **614.9 Mops/sec (32线程)**
- 说明 Stage 1 和 Stage 2 的优化（chunk 分配、writer_hwm 分离）非常有效
- 写入热路径本身已经接近或达到目标性能（200M+ ops/s）

#### ❌ **Merge 成为严重瓶颈**
- **真实吞吐**（包含 merge）在 8+ 线程时急剧下降：
  - 4线程: 58.8 Mops/sec
  - 8线程: **5.66 Mops/sec** (下降 90%)
  - 16线程: **0.42 Mops/sec** (下降 99%)
  - 32线程: **0.21 Mops/sec** (下降 99.6%)

- **Merge CPU Ratio** 在 8+ 线程时接近 100%：
  - 说明几乎所有时间都在做 merge，写入线程很快完成，但 merge 线程成为单核瓶颈
  - Merge 是**单线程串行**的，无法利用多核

#### ⚠️ **数据丢失问题**
- **32线程时有 27,593 个 alloc_failures**
- 说明 buffer 满了，写入失败但没有重试机制，导致数据丢失
- 这是一个**功能级别的 bug**，需要修复

### 1.3 性能瓶颈分析

**当前架构的问题**：
1. **Merge 单线程瓶颈**：所有写入完成后，只有一个 merge 线程在串行处理所有 slot
2. **没有 pipeline**：写入和 merge 是分离的，写入完成后才开始 merge
3. **Buffer 容量不足**：32线程时 buffer 很快写满，导致 alloc_failures

**与目标对比**：
- 目标：≥200M ops/s (整体吞吐，包含 merge)
- 当前：最高 110.2 Mops/sec (2线程)，32线程时只有 0.21 Mops/sec
- **差距巨大**：需要并行化 merge 或实现真正的 pipeline

---

## 二、Lookup 性能测试结果

### 2.1 测试结果

| 线程数 | 查询次数 | 命中数 | Hit Rate | 吞吐 (Mops/sec) |
|--------|---------|--------|----------|----------------|
| 1      | 1,024,000 | 0    | 0%       | 21.3           |
| 2      | 1,024,000 | 0    | 0%       | 14.4           |
| 4      | 1,024,000 | 0    | 0%       | 17.9           |
| 8      | 1,024,000 | 0    | 0%       | 28.4           |
| 16     | 1,024,000 | 0    | 0%       | 38.1           |
| 32     | 1,024,000 | 0    | 0%       | 37.7           |

### 2.2 严重问题：数据未成功 Merge 到 Tree

**所有测试都显示**：
```
[BuildIndex] Done. Tree records: 0
[ERROR] Tree is empty after build! Lookup test will fail.
```

**问题分析**：
- `flush_all_and_merge_once` 调用后，`CountTreeRecords(tree)` 返回 0
- 说明 `MergeWorker::run_once()` 没有成功将 buffer 中的数据 merge 到 tree
- 这是一个**功能级别的 bug**，需要立即修复

**可能的原因**：
1. `seal_all_slots_for_flush()` 没有正确标记所有 slot 为 SEALED
2. `MergeWorker::run_once()` 的逻辑有问题，没有处理所有 SEALED 的 slot
3. `build_blocks_from_slot()` 或 `merge_run_into_leaf()` 有 bug，导致数据没有写入 tree

---

## 三、Scan 性能测试结果

### 3.1 测试结果

| 线程数 | Scan 操作数 | 返回记录数 | 平均记录/scan | 吞吐 (Kops/sec) |
|--------|------------|-----------|-------------|----------------|
| 1      | 5,120      | 0         | 0           | 5435.2         |
| 2      | 5,120      | 0         | 0           | 2317.8         |
| 4      | 5,120      | 0         | 0           | 3168.3         |
| 8      | 5,120      | 0         | 0           | 2735.0         |
| 16     | 5,120      | 0         | 0           | 2779.6         |
| 32     | 5,120      | 0         | 0           | 2553.6         |

### 3.2 同样的问题：Tree 为空

**所有测试都显示**：
```
[BuildIndex] Done. Tree records: 0
Total returned records : 0
```

**问题分析**：
- 与 Lookup 相同的问题：数据没有成功 merge 到 tree
- 即使 query 生成逻辑已经修复（确保 start_key 在数据范围内），但因为 tree 为空，所以返回 0 条记录
- 当前的 "吞吐" 数字（2-5 Kops/sec）实际上是在测"空扫描"的控制路径，没有数据路径的性能

---

## 四、问题总结

### 4.1 功能级别的问题（必须修复）

1. **❌ Merge 失败：数据未写入 Tree**
   - `flush_all_and_merge_once` 后 tree 为空
   - 导致 Lookup/Scan 测试完全失效
   - **优先级：P0（最高）**

2. **❌ 数据丢失：alloc_failures > 0**
   - 32线程时有 27,593 个失败
   - 需要实现 backpressure 或重试机制
   - **优先级：P0（最高）**

### 4.2 性能瓶颈（需要优化）

1. **⚠️ Merge 单线程瓶颈**
   - 8+ 线程时真实吞吐下降 90%+
   - 需要并行化 merge 或实现 pipeline
   - **优先级：P1（高）**

2. **⚠️ Buffer 容量不足**
   - 32线程时很快写满
   - 需要增大 buffer 或实现动态扩容
   - **优先级：P1（高）**

### 4.3 测试方法已修正

✅ **Insert 吞吐计算**：已改为使用 wall time，真实反映包含 merge 的整体性能  
✅ **Alloc failures 检测**：已添加警告，能及时发现数据丢失  
✅ **Sanity check**：已添加，能及时发现 tree 为空的问题  

---

## 五、下一步行动建议

### 立即修复（P0）

1. **修复 Merge 失败问题**
   - 检查 `flush_all_and_merge_once` 的实现
   - 检查 `MergeWorker::run_once()` 是否正确处理所有 SEALED slot
   - 添加调试日志，定位数据丢失的位置

2. **修复 alloc_failures**
   - 实现 backpressure：buffer 满时阻塞写入线程，等待 merge 完成
   - 或实现重试机制：指数退避重试，直到成功

### 性能优化（P1）

1. **并行化 Merge**
   - 将 merge 任务按 leaf 分片，多线程并行处理
   - 或实现真正的 pipeline：写入和 merge 同时进行

2. **优化 Buffer 管理**
   - 增大 buffer 容量（根据线程数和写入速率动态计算）
   - 或实现动态扩容机制

---

## 六、结论

### 当前状态

- ✅ **写入热路径性能优秀**：峰值可达 614.9 Mops/sec (32线程)
- ❌ **整体性能受限于 Merge**：真实吞吐在 8+ 线程时急剧下降
- ❌ **功能级别的问题**：Merge 失败导致 Lookup/Scan 测试失效

### 与目标对比

| 指标 | 目标 | 当前最佳 | 当前最差 | 状态 |
|------|------|---------|---------|------|
| Insert 整体吞吐 | ≥200M ops/s | 110.2 Mops/sec (2线程) | 0.21 Mops/sec (32线程) | ❌ 未达标 |
| Insert 写入峰值 | ≥200M ops/s | 614.9 Mops/sec (32线程) | 74.5 Mops/sec (1线程) | ✅ 已达标 |
| Lookup 功能 | 正常工作 | ❌ Tree 为空 | ❌ Tree 为空 | ❌ 失效 |
| Scan 功能 | 正常工作 | ❌ Tree 为空 | ❌ Tree 为空 | ❌ 失效 |

**总体评价**：
- 写入热路径优化**非常成功**，已经达到甚至超过目标
- 但 Merge 机制存在**严重问题**，需要立即修复
- 在修复 Merge 问题之前，无法进行有效的性能对比



