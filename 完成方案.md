### TSDB 项目总结报告

#### 1. 项目目标与整体架构

本项目实现了一个**内存型时间序列数据库（TSDB）核心引擎**，重点关注：

- **高并发写入吞吐**
- **在内存中保持有序的数据结构（SB-Tree 风格）**
- **写入路径与合并路径解耦（双缓冲 + 后台 merge）**
- **支持基本的查询能力（全量扫描 + 范围查询）**

整体架构可以概括为四层：

1. **写入缓冲层（WDS / RDS）**：双 Buffer + Slot（SWMR）  
2. **后台合并层（MergeWorker + Flipper）**：周期性将 RDS 数据归并到 Tree  
3. **持久结构层（SB-Tree 多叶子结构）**：按 key 范围分片的叶子数组，每个叶子内有序  
4. **读路径层（Reader）**：将 Tree 与 RDS 的数据合并，提供 scan 和 range query

---

#### 2. 核心数据结构与模块

##### 2.1 Record / Slot / Buffer / BufferManager

- **`Record`**

  ```cpp
  struct Record {
    uint64_t key;
    uint64_t value;
    uint32_t epoch; // 预留字段
  };
  ```

- **Slot（单写多读 SWMR 单元）**

  - `recs`：固定大小的连续记录数组（按 `SLOT_SIZE_BYTES` / `sizeof(Record)` 计算容量）
  - `hwm`：`std::atomic<uint16_t>`，表示当前 slot 内有效记录数
  - `state`：`WRITING / SEALED / CONSUMED`，表示写入/封口/已消费状态
  - 提供语义化方法：
    - `append_pos()`：返回追加位置（基于 `hwm.fetch_add`）
    - `size_acquire()`：读取当前记录数
    - `reset_for_write()`：将 slot 重置为 WRITING

- **Buffer**

  - 一组 `Slot` 的集合，代表某个时间区间内接收的写入批次
  - 成员：
    - `slots`：`Slot` 数组
    - `slot_capacity`：slot 数量
    - `alloc_idx`：当前分配到哪个 slot
    - `state`：`WRITING / SEALED`

- **BufferManager**

  - 管理两个 Buffer（双缓冲）：`buffers[2]`
  - 关键方法：
    - `allocate_slot()`：从当前写 buffer 分配一个 Slot
    - `flip_buffers()`：切换当前写 Buffer，将旧 Buffer 标记为 SEALED
    - `seal_all_slots_for_flush()`：在收尾时，将仍处于 WRITING 的 Slot 封口并允许消费

通过 **Slot（SWMR） + 双 Buffer**，实现了写入路径的高并发与读/merge 路径的解耦。

---

##### 2.2 写入引擎：Engine

- 对外暴露的核心接口：

  ```cpp
  class Engine {
  public:
    void insert(uint64_t key, uint64_t value);
  };
  ```

- 内部依赖：
  - `BufferManager *bm`：管理写入缓冲
  - `SBTree *tree`：后端持久结构
  - `thread_local ThreadLocalCtx tls_ctx`：每个线程持有当前使用的 `Slot*` 与 Buffer index

- 写入策略（简述）：
  1. 线程优先使用线程本地的 `current_slot`，在 Slot 容量未满且 Buffer 未翻转的情况下，直接在 Slot 内追加记录（fast path）。
  2. 当 Slot 满或者 Buffer 被 flip 时：
     - 将当前 Slot 封口（state 切到 SEALED）；
     - 向 `BufferManager::allocate_slot()` 请求新 Slot；
     - 更新本线程的 `current_slot` 和 buffer index。
  3. `insert` 不直接触碰 SB-Tree，所有合并工作交给后台 MergeWorker。

优点：

- 单线程写 slot，避免 slot 级别的写写竞争。
- 多线程通过 BufferManager 和 ThreadLocalCtx 解耦，各自维护自己的写入进度。

---

##### 2.3 SB-Tree 多叶子结构

- **`SBTree`**：使用固定大小的叶子数组 `leaves_[kLeafCount]`（目前为 4 个叶子）。

  - `locate_leaf(key)`：依据 key 的高位 bit 将 key route 到某个叶子。
  - `leaf_at(idx)` / `leaf_at_mut(idx)`：调试与 merge 过程中访问叶子的接口。
  - `merge_run_into_leaf(leaf, run)`：将一批有序记录 merge 到指定叶子中。

- **`SBTreeLeaf`**

  - 内部使用一个 `std::vector<Record> data_` 存储有序记录。
  - `merge_runs(newrun)` 实现：
    1. 假设 `newrun` 已按 key 排序；
    2. 与现有 `data_` 做归并，保持整体有序；
    3. 更新 `min_key_` / `max_key_`，供 range query 做剪枝。

该层本质上是一个**分段有序数组**结构，未来可以自然演化为 SB-Tree 论文中的完整实现（包含内部节点等）。

---

##### 2.4 MergeWorker 与 Flipper

- **MergeWorker**

  - 负责从已 SEALED 的 Buffer 中消费 Slot，将数据路由到各个叶子的 batch，并最终合并到 `SBTree`。
  - 流程：
    1. 扫描两个 Buffer：
       - 只处理 `BUFFER_STATE_SEALED` 的 Buffer；
       - 只处理 `SLOT_STATE_SEALED` 的 Slot。
    2. 对每个 SEALED Slot：
       - 按 key 路由到 `leaf_batches[leaf_idx]`；
       - 将 Slot 标记为 CONSUMED（以便重复利用或释放）。
    3. 对每个 leaf 的 batch：
       - `std::sort` 按 key 排序；
       - 调用 `SBTree::merge_run_into_leaf` 合并到对应叶子。

- **Flipper**

  - 独立线程周期性执行：
    - `flip_buffers()`：将当前写 Buffer 切换，旧 Buffer 进入 SEALED 状态。
    - `MergeWorker::run_once()`：处理所有 SEALED Buffer，将数据推入 `SBTree`。

这种设计确保：

- 写线程只负责“写 + 偶尔翻 Buffer”，路径简洁；
- merge 的复杂逻辑集中在后台线程中，便于优化与扩展。

---

##### 2.5 Reader / Query

- **`Reader::scan_all()`**：
  - 从所有 SBTree 叶子拉取数据，合并成一个整体有序的 Tree 视图；
  - 再从所有 SEALED Buffer 的 SEALED Slot 中拉取记录，排序；
  - 最终将 Tree 结果和 RDS 结果两路归并，得到全局排序的结果。

- **`Reader::range_query(key_lo, key_hi)`**：
  - Tree 部分：
    - 依据每个叶子的 `min_key` / `max_key` 做范围剪枝；
    - 在被命中的叶子内做线性扫描，筛选出 `[key_lo, key_hi]` 区间记录。
  - RDS 部分：
    - 遍历所有 SEALED Slot；
    - 对 slot 内所有记录做线性过滤，并收集到 RDS 部分结果中；
    - RDS 结果排序；
  - 最终将 Tree 和 RDS 的结果按 key 归并返回。

当前实现以**正确性和简洁性**为优先，为后续引入更复杂的索引（如 per-slot min/max、Bloom filter）预留空间。

---

#### 3. Benchmark 体系与当前性能

##### 3.1 端到端 Benchmark：`tsdb_benchmark`

- 模拟场景：

  - 256 条“传感器序列”；
  - 总共 2,000,000 条记录；
  - 每条记录 key = `(series_id << 48) | timestamp_low_48`，时间单调递增；
  - 多线程写入，线程数可配置（默认等于硬件并发）。

- 测量指标：

  - `insert throughput`：只看写线程阶段的 `Engine::insert` 调用吞吐。
  - `front throughput`：缓冲区中记录数 / 总时间。
  - `tree throughput`：最终 SBTree 中记录数 / 总时间。
  - 线程时间统计：min / max / avg / median。
  - merge 迭代次数与 merge 总时间占比。
  - 最后检查：`Tree + Buffers` 的记录数与成功插入次数是否一致。

- 当前表现（典型运行，Release 模式，32 线程）：

  - `insert throughput`：约 **40–70 Mops/sec**，视运行波动与 merge 占比而定。
  - merge 时间占 total 的 20%–60%，视工作负载与时间片分配而变。
  - 全部检查通过，记录数一致。

##### 3.2 纯插入 Benchmark：`tsdb_insert_bench`

- 目的：专门测量 `Engine::insert` 的“理论峰值”性能，不受 flipper / merge 干扰。
- 与 `tsdb_benchmark` 共用：
  - 数据生成方式；
  - 写线程分配方式（按 series 分配任务）。
- 差异：
  - 不启动 flipper 线程，不调用 MergeWorker；
  - 写完数据后，直接按写线程的中位时间统计 `insert throughput`。

- 当前表现（Release，32 线程，多次测试）：

  - `insert throughput`：稳定在 **~110 Mops/sec** 左右（108–119 Mops 波动）。
  - 说明当前 `Engine::insert` 的实现仍然保持了接近“原始版本”的高写入吞吐能力。

---

#### 4. 已实现能力与可提升方向

##### 已实现的核心能力

- **写入路径**
  - 多线程高并发写入；
  - Slot 级别 SWMR，避免复杂锁竞争；
  - 双 Buffer 写入策略，便于在后台异步合并。

- **后台合并**
  - MergeWorker 能将 RDS 数据正确路由并合并到 SBTree；
  - 支持多叶子结构，具备进一步扩展为真正 SB-Tree 的基础。

- **读路径**
  - 全量扫描（Tree + RDS）；
  - range query（利用 leaf min/max 进行初步剪枝）。

- **性能测试体系**
  - `tsdb_benchmark`：端到端吞吐、merge 占比、正确性验证；
  - `tsdb_insert_bench`：纯写入性能的基准测试。

##### 可提升的方向（简要）

- **写路径微优化**
  - 减少 `Engine::insert` 热路径上的 `acquire` / `acq_rel` 调用次数；
  - 将部分状态检查从 fast path 移到 slow path。

- **Merge 并行化与优化**
  - 按叶子维度对 merge 阶段并行化（每个 leaf 一个任务）；
  - 对 `leaf_batches` 做更高效的归并策略。

- **range query 性能**
  - 为 Slot 引入 `min_key` / `max_key`，在 RDS 部分做剪枝；
  - 后续可叠加更复杂的轻量索引结构。

- **Buffer 分配与线程局部优化**
  - 通过 thread-local slot 预分配减少 `alloc_idx` 的竞争；
  - 优化 `ThreadLocalCtx` 的 slot 复用策略。

---

### 总结

当前版本已经完成了一个**功能完整、结构清晰、性能可观**的 TSDB 内存引擎原型：

- 支持多线程高并发写入、双缓冲、后台合并、多叶子 SB-Tree、基础查询；
- 拥有较完善的 benchmark 体系，能分别观测“纯写入”与“端到端”性能；
- 在此基础上，可以围绕 **merge 并行化、写路径微调、查询优化** 继续迭代，将系统从“原型级”推向“工程化优化版”。